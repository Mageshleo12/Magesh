import numpy as np
import pandas as pd
from google.colab import files
import matplotlib.pyplot as plt
uploaded = files.upload()
uploaded = files.upload()
import io
data = pd.read_csv(io.StringIO(uploaded['heart.csv'].decode('utf-8')))
print(data.head())
data.shape
data.plot.scatter(x='age', y='chol')
data.groupby('target').size()
x = data.iloc[:,0:13].values
y = data.iloc[:,13].values
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=2)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
datanormal = sc.fit_transform(x_train)
datanormal = sc.transform(x_test)
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.model_selection import cross_val_score

classifier = KNeighborsClassifier(n_neighbors = 3)

classifier.fit(x_train, y_train)

prediction = classifier.predict(x_test)
#prediction.values
print(prediction)
classifier.score(x_test,y_test)
from sklearn.naive_bayes import GaussianNB
classifier1 = GaussianNB()
classifier1.fit(x_train, y_train)
prediction1 = classifier1.predict(x_test)
print(prediction1)
accuracy1 = accuracy_score(y_test, prediction1)*100
print('Accuracy of our model is equal ' + str(round(accuracy1, 2)) + ' %.')
len(prediction)
cm = confusion_matrix(y_test, prediction)
cm
accuracy = accuracy_score(y_test, prediction)*100
print('Accuracy of our model is equal ' + str(round(accuracy, 2)) + ' %.')
prediction = classifier.predict(x_test)
##print(y_pred)
print("Score is",classifier.score(x_test,y_test))
for i in range (1,30,2):
  classifier2 = KNeighborsClassifier(n_neighbors=i)
  classifier2.fit(x_train, y_train)
  print("For k = %d accuracy is"%i,classifier2.score(x_test,y_test))
  # creating list of K for KNN
k_list = list(range(1,30,2))
###print(k_list)
# creating list of cv scores
cv_scores = []

# perform 10-fold cross validation
for k in k_list:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, x_train, y_train, cv=10, scoring='accuracy')
    cv_scores.append(scores.mean())
    import seaborn as sns
%matplotlib inline
# changing to misclassification error
MSE = [1 - x for x in cv_scores]
plt.figure()
plt.figure(figsize=(15,10))
plt.title('The optimal number of neighbors', fontsize=20, fontweight='bold')
plt.xlabel('Number of Neighbors K', fontsize=15)
plt.ylabel('Misclassification Error', fontsize=15)
sns.set_style("whitegrid")
plt.plot(k_list, MSE)
plt.show()
# finding best k
print(min(MSE))
print(MSE.index(min(MSE)))
##k_list[MSE.index(min(MSE))]
best_k = k_list[MSE.index(min(MSE))]
print("The optimal number of neighbors is %d." % best_k)
data1=pd.DataFrame()
data1['prediction']=prediction
data1['actual']=y_test
data1['prediction1']=prediction1
data1
